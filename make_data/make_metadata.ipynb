{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "taken-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate speaker embeddings and metadata for training\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from factory.MetaDV import MetaDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.load(\"../model/static/metadv_tw.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "returning-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY DIFFERENT CONTENT OF VOICE IN YOUR DATA\n",
    "num_uttrs = 100\n",
    "len_crop = 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "under-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: ./spmel\n"
     ]
    }
   ],
   "source": [
    "# Directory containing mel-spectrograms\n",
    "rootDir = './spmel'\n",
    "dirName, subdirList, _ = next(os.walk(rootDir))\n",
    "print('Found directory: %s' % dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "offshore-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "    if pad_size <= 0:\n",
    "        return array\n",
    "    npad = [(0, 0)] * array.ndim\n",
    "    npad[axis] = (0, pad_size)\n",
    "    return np.pad(array, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "apart-efficiency",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing speaker: p1\n",
      "Processing speaker: p2\n",
      "Processing speaker: 劉大偉\n",
      "Processing speaker: 劉安婷\n",
      "Processing speaker: 吳淡如\n",
      "Processing speaker: 呂世浩\n",
      "Processing speaker: 姜莫莉\n",
      "Processing speaker: 廖敏惠\n",
      "Processing speaker: 徐裴翊\n",
      "Processing speaker: 曾博恩\n",
      "Processing speaker: 林懷民\n",
      "Processing speaker: 林昶佐\n",
      "Processing speaker: 柯文哲\n",
      "Processing speaker: 淨空法師\n",
      "Processing speaker: 莊淑芬\n",
      "Processing speaker: 葉丙成\n",
      "Processing speaker: 蔣勳\n",
      "Processing speaker: 視網膜\n",
      "Processing speaker: 賴佩霞\n",
      "Processing speaker: 郭婞淳\n",
      "Processing speaker: 鍾瑩瑩\n",
      "Processing speaker: 陳崇文\n",
      "Processing speaker: 陳文茜\n",
      "Processing speaker: 馮翊綱\n"
     ]
    }
   ],
   "source": [
    "speakers = []\n",
    "for speaker in sorted(subdirList):\n",
    "    print('Processing speaker: %s' % speaker)\n",
    "    utterances = []\n",
    "    utterances.append(speaker)\n",
    "    _, _, fileList = next(os.walk(os.path.join(dirName,speaker)))\n",
    "    fileList = fileList[:num_uttrs]\n",
    "    # make speaker embedding\n",
    "    assert len(fileList) >= num_uttrs\n",
    "    idx_uttrs = np.random.choice(len(fileList), size=num_uttrs, replace=False)\n",
    "    embs = []\n",
    "    for i in range(num_uttrs):\n",
    "        tmp = np.load(os.path.join(dirName, speaker, fileList[idx_uttrs[i]]))\n",
    "        # pad if the current one is too short   \n",
    "        if tmp.shape[0] < len_crop:\n",
    "            tmp = pad_along_axis(tmp,len_crop)\n",
    "            melsp = torch.from_numpy(tmp[np.newaxis,:, :]).cuda()\n",
    "        else:\n",
    "            melsp = torch.from_numpy(tmp[np.newaxis,:, :]).cuda()\n",
    "        emb = C(melsp)[1]\n",
    "        embs.append(emb.detach().squeeze().cpu().numpy())    \n",
    "           \n",
    "    utterances.append(np.mean(embs, axis=0))\n",
    "    # create file list\n",
    "    for fileName in sorted(fileList):\n",
    "        utterances.append(os.path.join(speaker,fileName))\n",
    "    speakers.append(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "raising-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(rootDir, 'train.pkl'), 'wb') as handle:\n",
    "    pickle.dump(speakers, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-today",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
